\chapter{Lecture 5-7: Acrobots, Cart-poles, and Quadrotors}
\section{Introduction}
So far we have covered the following topics:
\begin{itemize}
\item Manipulator Equations
\item Feedback Linearization
\item Optimal Control
\item Value Iteration (Algorithm for DDP in discrete time)
\end{itemize}
After introducing basics of "classic" non-linear control, we started thinking about control as optimization.

In this chapter the most simple standard models for underactuated robots are introduced. These low-dimensional systems are supposed to capture the essence of the problem without all the real-world complexity of advanced systems. 

\section{System Dynamics: Manipulator Equations}
The Acrobot is a simple underactuated system since it has two DoF. But, in comparison to the double pendulum, it only has one actuator at the elbow so that 
$\myM{B}=\begin{bmatrix} 0 & 1 \end{bmatrix}^T $.
Manipulator Equations: 
\begin{equation*}
\myM{M}(\myM{q})\myM{\ddot{q}}+\myM{C}(\myM{q,\dot{q}})\myM{\dot{q}}=\tau_g(\myM{q})+\myM{Bu}.
\end{equation*}
The goal is to swing-up and balance while satisfying some torque limits. One possible approach to solve this problem is using \textit{value iteration}. But the grids would have to be very fine, in order to get a good solution. There are better tools to solve this problem: LQR!


\section{Balancing for Acrobot and Cart-Pole}
For both the Acrobot and the Cart-Pole systems, we will begin by designing a linear controller which can balance the system when it begins in the vicinity of the unstable fixed point. To accomplish this, we will linearize the nonlinear equations about the fixed point, examine the controllability of this linear system, then using linear quadratic regulator (LQR) theory to design our feedback controller.

What we'll do to accomplish the balancing: 
\begin{enumerate}
\item Linearizing the manipulator equations
\item Check controllability of linear systems
\item Use LQR to design a feedback controller
\end{enumerate}
\subsection{Recap: LQR}
We have a linear time-invariant system in state-space form
\begin{equation*} 
\myM{\dot{x}}=\myM{Ax}+\myM{Bu},
\end{equation*}
the cost function is 
\begin{equation*} 
J = \int_0^{\infty}[\myM{x}^T\myM{Qx}+\myM{u}	^T\myM{Ru}]dt,
\end{equation*}
and the goal is to find the optimal cost-to-go function $J^\star(\myM{x})$ which satisfies the Hamilton-Jacobi-Bellman equation.
This yields 
\begin{equation*} 
J^\star(\myM{x}) = \myM{x}^T\myM{Sx}
\end{equation*}
and the optimal control policy 
\begin{equation*} 
\myM{u}^\star=\myM{Kx}.
\end{equation*}
In the end, this means you get the control policy and the cost-to-go function by
\begin{equation*} 
\myM{K,S}=LinearQuadraticRegulator(\myM{A}, \myM{B}, \myM{Q}, \myM{R}).
\end{equation*}
So you set $\myM{A}, \myM{B}$ from linearization and choose $\myM{Q}, \myM{R}$ and receive an optimal controller.

\subsection{Linearization of Nonlinear Systems}
\textbf{Problem:} Our systems are non-linear! How shall we apply Linear-Quadratic Control?!

\textbf{Solution:} We linearize our system around a specific fixed point.

But we need to be aware that our linearization only is valid within a certain area around this point. If you go to far away from it, the non-linearity overwhelms your solution. 

One Optimal Control Algorithm therefore is to combine multiple LQR Controllers that treat all relevant fixed points in order to handle the relevant workspace. 

\section{Throwback: Hand-Designed Control}
\begin{itemize}
\item Optimal control is a powerful framework for solving control problems via optimization.
\item Solving OC problems for non-linear systems is hard!
\item Sometimes we would be happy to just have any controller (And sometimes they turn out to be even better).
\item But how can we proof this "hand-designed" are any good? 
\end{itemize}

\section{Partial Feedback Linearization (Acrobot,Cart-pole)}
Although we cannot always simplify the full dynamics of the system, it is still possible to linearize a portion of the system dynamics. The technique is called partial feedback linearization.
\begin{itemize}
\item \textit{Collocated} PFL: A controller which linearizes the dynamics of the \textit{actuated} joints
\item \textit{Non-Collocated} PFL: A controller which linearizes the dynamics of the \textit{unactuated} joints
\end{itemize}
One of the most important lessons from partial feedback linearization, is the idea that if you have m actuators, then you basically get to control exactly m quantities of your system.

-> We proof that they are stable. 

\section{Swing-Up Control: Energy Shaping (Acrobot,Cart-pole)}
If we seek to design a nonlinear feedback control policy which drives the simple pendulum from any initial condition to the unstable fixed point, a very reasonable strategy would be to use actuation to regulate the energy of the pendulum to place it on this homoclinic orbit, then allow the system dynamics to carry us to the unstable fixed point.

This idea turns out to be a bit more general than just for the simple pendulum. As we will see, we can use similar concepts of `energy shaping' to produce swing-up controllers for the acrobot and cart-pole systems. It's important to note that it only takes one actuator to change the total energy of a system.

The basic Idea for the swing-up control is to
\begin{enumerate}
\item Use collocated PFL to simplify the dynamics
\item Use energy shaping to regulate the pendulum to its homoclinic orbit
\item Add a few terms to make sure that the cart stays near the origin
\end{enumerate}


\section{Differential Flatness (Quadrotors)}
The task we'll consider for quadrotors is trajectory optimization:

How can you find a feasible trajectory through state space for the quadrotor, even if there are obstacles to avoid that are only known at runtime? 

Trajectory design, and especially trajectory optimization, is a big idea that we will explore more thoroughly later in the text. But there is one idea that I would like to present here, because in addition to being a very satisfying solution for quadrotors, it is philosophically quite close to the idea of partial feedback linearization. That idea is called differential flatness.

\begin{itemize}
\item Similar idea as PFL: Given a trajectory of m (number of actuators) coordinates. 
\item Then, the control input and all left states can be guessed
\item Condition: Trajectory needs to be four-times differentiable
\end{itemize}

2D-Quadrotor Example (m=2): Given x,y of trajectory, guess resulting jaw and control input.

3D-Quadrotor Example (m=4): Given x,y,z,jaw guess roll, pitch and control for all motors.

